{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-]","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Readings","text":""},{"location":"#what-is-readings","title":"What is Readings?","text":"<p>A repo that records what I've learned over time.</p> <ul> <li> Github Repo. Repo for source code.</li> </ul>"},{"location":"gumbel_softmax/","title":"Gumbel distribution and Gumbel-softmax","text":""},{"location":"gumbel_softmax/#extreme-value-distribution","title":"Extreme value distribution","text":"<p>We derive the distribution of max of <code>n</code> samples drawn from a distribution in two ways. Let's assume that the PDF of the distribution is given by \\(p(x)\\) and the CDF is given by \\(F(x)\\). Thus means \\(F'(x) = f(x)\\).</p> <p>1. A combinatorial way to derive the distribution</p> <ul> <li>Probability(max of <code>n</code> samples is <code>M</code>) </li> <li>= Probability(<code>n-1</code> samples &lt; <code>M</code>, one sample is equal to <code>M</code>)</li> <li>= \\({n\\choose n-1}F(M)^{n-1}f(M)\\)</li> <li>= \\(nF(M)^{n-1}f(M)\\)</li> </ul> <p>2. A calculus centric way to derive the distribution</p> <ul> <li>Probability(all <code>n</code> samples are less than <code>M</code>)</li> <li>= \\(\\text{CDF of (M)}^n\\)</li> <li>= \\(F(M)^n\\)</li> <li>\\(\\Rightarrow \\text{PDF of (M) = }\\) \\(nF(M)^{n-1}f(M)\\)</li> </ul> <p>Examples</p> <ol> <li> <p>If \\(p(x)\\) is a uniform distribution between <code>0</code> and <code>1</code> then:</p> <ul> <li>Probability(max of <code>n</code> samples = <code>X</code>) = \\(nX^{n-1}\\)</li> </ul> </li> <li> <p>If \\(p(x)\\) is an exponential distribution then \\(p(x) = e^{-x}\\) and \\(P(x) = 1-e^{-x}\\). Then:</p> <ul> <li>Probability(max of <code>n</code> samples = <code>M</code>) = \\(ne^{-M}(1-e^{-M})^n\\)</li> </ul> </li> </ol>"},{"location":"gumbel_softmax/#deriving-gumbel-distribution","title":"Deriving Gumbel distribution","text":"<p>In the second example, we would like to pick a value of <code>M</code> so that the distribution term takes the form of an expression we are all familiar with. Let \\(M = X + \\ln(n)\\) for some value \\(X\\). Then we have \\(e^{-M} = e^{-X}/n\\). This gives us:</p> <ul> <li>Probability(max of <code>n</code> samples = \\(X + \\ln(n)\\))</li> <li>\\(= e^{-X}(1 - \\frac{e^{-X}}{n})^n\\)</li> </ul> <p>Now as \\(n \\rightarrow \\infty\\):</p> <ul> <li>Probability(max of samples = \\(X + \\ln(n)\\)) = \\(e^{-X}e^{-e^{-X}}\\)</li> <li>Probability(all samples \\(\\le X + \\ln(n)\\)) = \\(e^{-e^{-X}}\\) which is the CDF of the above distribution.</li> </ul> <p>More generally, the distribution is parameterized by \\(\\mu, \\beta\\) like so:</p> \\[P(X;\\mu, \\beta) = e^{-e^{(x - \\mu)/\\beta}}\\]"},{"location":"gumbel_softmax/#gumbel-reparameterization-trick","title":"Gumbel reparameterization trick","text":"<p>Problem</p> <p>Given a discrete distribution with probabilities \\(x_i,\\ i=1\\ldots n,\\ \\sum_i {x_i} = 1\\), how can we draw samples from this distribution in a differentiable manner? In other words, how can the samples be a function of \\(x_i\\)?</p> <p>Solution</p> <p>Add Gumbel noise to the logits of the distribution and then apply argmax. The Gumbel noise is drawn from a Gumbel distribution with parameters \\(\\mu = 0, \\beta = 1\\). </p> <p>Since argmax is not differentiable, we replace it with softmax. Thus there are two steps to the Gumbel-softmax trick:</p> <ol> <li> <p>Draw samples from the Gumbel distribution and add it to the logits of the distribution. The argmax of this array has the same distribution as the original distribution. We will prove it next.</p> </li> <li> <p>Apply softmax to the result instead of argmax to make the operation differentiable.</p> </li> </ol> <p>Proof of the first point</p> <p>We are given the following:</p> <ul> <li>Logits \\(x_i,\\ i=1\\ldots n\\) which means \\(p_i = \\frac{e^{x_i}}{\\sum_j e^{x_j}}\\)</li> <li>Gumbel noise \\(g_i\\) drawn from \\(Gumbel(0, 1)\\)</li> </ul> <p>We want to prove that probability(\\(g_M + x_M\\) is the max over \\(M\\)) = \\(p_M\\) for some \\(M\\).</p> <ul> <li>Probability(\\(g_M + x_M\\) is the max value)</li> </ul> <p>= \\(\\int_{-\\infty}^{\\infty} \\text{prob} (g_i + x_i \\le g_M + x_M) . \\text{prob} (g_M) \\,dg_M\\)</p> <p>= \\(\\int_{-\\infty}^{\\infty} \\prod_{i \\ne M} e^{-e^{g_M + x_M - x_i}} e^{-g_M} e^{-e^{-g_M}}   \\,dg_M\\)</p> <p>= \\(\\int_{-\\infty}^{\\infty} \\prod_{i} e^{-e^{g_M + x_M - x_i}} e^{-g_M}   \\,dg_M\\)</p> <p>= \\(\\int_{-\\infty}^{\\infty} \\prod_{i} e^{-{e^{-g_M}}{e^{-x_M}}(\\sum_i e^x_i)} e^{-g_M}   \\,dg_M\\)</p> <p>Now substitute \\(e^{-g_M} = t \\Rightarrow e^{-g_M} dg_M = -dt\\):</p> <p>= \\(\\int_{0}^{\\infty} e^{-Ct}   \\,dt\\) where \\(C = \\frac{\\sum_i e^x_i}{e^{x_M}}\\)</p> <p>= \\(\\frac{1}{C} = \\frac{e^{x_M}}{\\sum_i e^x_i} = p_M\\)</p> <p>This completes the proof.</p> <p>Replacing argmax with softmax</p> <p>Note that this still needs argmax which is not differentiable. If we use argmax, the output is a one hot vector. If we use fotmax, the output is a vector which is a function of the logits.</p> <p>Example</p> <p>We are given the array of logits with Gumbel noise added to them:</p> \\[[x_1, x_2, x_3] + [g_1, g_2, g_3]\\] <p>The argmax of this array may look like:</p> \\[[0, 1, 0]\\] <p>The softmax of this array will look like:</p> \\[[e^{x_1 + g_1}, e^{x_2 + g_2}, e^{x_3 + g_3}]/\\sum_i e^{x_i + g_i}\\] <p>This can be used in a neural network to make the operation differentiable. Usually temperature is added to the softmax operation:</p> \\[\\text{softmax}([x_1 + g_1, x_2 + g_2, x_3 + g_3]/\\tau)\\] <p>where \\(\\tau\\) is the temperature parameter.</p>"},{"location":"gumbel_softmax/#a-common-confusion-in-gumbel-softmax","title":"A common confusion in Gumbel-softmax","text":"<p>One may ask: why not just use the softmax of the logits directly? Why add Gumbel noise?</p> <p>The answer to this question comes from the observation that the softmax should converge to argmax as the temperature parameter \\(\\tau\\) goes to zero. If we use the softmax of the logits directly with a very small temperature, the output will always converge to the same one hot vector (corresponding to the largest value in the logits). We are not actually sampling from the distribution. If we take the softmax of logits with Gumbel noise, the output will be a sample from the distribution. This is what we want.</p>"},{"location":"memorize-sherman-morrison-formula/","title":"How to memorize the Sherman-Morrison Formula","text":"<p>The Sherman-Morrison formula tells us how we can find the inverse of the matrix \\(I_n+M\\) in certain situations, where \\(M\\) is of rank one. In the literature, the matrix \\(M\\) is often expressed as the product \\(uv^T\\) of vectors \\(u\\) and \\(v\\) coming from \\(\\mathbb{R}^n\\).</p> <p>This note is not intended to show how to derive the Sherman-Morrison formula in a rigorous fashion. Instead, it serves as a cheatsheet for how one can recall these identities effortlessly in the future. At least, for me.</p> <p>For the sake of this note being self-contained, the formula are shown below.</p> <p>The Sherman-Morrison formula</p> <p>Let \\(A\\in\\mathbb{R}^{n\\times n}\\) be an invertible matrix and \\(u,v\\in\\mathbb{R}^n\\) be vectors. Then the matrix \\(A+uv^T\\) is invertible if and only if the scalar \\(1+v^TA^{-1}u\\) is nonzero. In that case, \\(\\big(A+uv^T\\big)^{-1}\\) has the explicit form:</p> \\[\\big(A+uv^T\\big)^{-1} = A^{-1}-\\frac{A^{-1}uv^TA^{-1}}{1+v^TA^{-1}u}\\tag{1}\\] <p>The equation \\((1)\\) can be obtained easily once we know what the exact form of \\(\\big(I_n+uv^T\\big)^{-1}\\) would be like, for \\(\\big(A+uv^T\\big)^{-1}\\) has the following expression:</p> \\[\\big(A+uv^T\\big)^{-1}=\\big(I_n+A^{-1}uv^T\\big)^{-1}A^{-1}\\tag{2}\\] <p>Therefore the key fact to deriving \\((1)\\) reduces to proving the following lemma:</p> <p>Lemma</p> <p>Let \\(u,v\\in\\mathbb{R}^n\\) be vectors. Then the matrix \\(I_n+uv^T\\) is invertible if and only if the scalar \\(1+v^Tu\\) is nonzero. In that case, \\(\\big(I_n+uv^T\\big)^{-1}\\) has the explicit form:</p> \\[\\big(I_n+uv^T\\big)^{-1} = I_n-\\frac{uv^T}{1+v^Tu}\\tag{3}\\] <p>\"Deriving\" the lemma</p> <p>Denote \\(uv^T\\) by \\(X\\). The form \\(\\big(I_n+X\\big)^{-1}\\) reminds me of expressing this term in another representation. Recalling the Taylor expansion taught in the calculus, I can symbolically write down the following:</p> \\[ \\begin{aligned} (I_n + X)^{-1}&amp;=I_n - X + X^2 - X^3 + \\cdots\\\\ &amp;=I_n - uv^T + uv^Tuv^T - uv^Tuv^Tuv^T + \\cdots\\\\ &amp;=I_n - u(1 - v^Tu + v^Tuv^Tu - v^Tuv^Tuv^Tu + \\cdots)v^T\\\\ &amp;=I_n - u(1 + v^Tu)^{-1}v^T \\end{aligned} \\] <p>The \"derivation\" illustrated above is currently the fastest way for me to retrieve the information of Sherman-Morrison formula out of my brain. I hope that this idea is useful for some of the readers as well.</p>"},{"location":"on-companion-matrices/","title":"On Companion Matrices","text":"<p>Let \\(F\\) be a field and \\(F[x]\\) be the polynomial ring in \\(x\\) over \\(F\\).</p> <p>Let \\(f(x)\\in F[x]\\) be a monic polynomial of degree \\(\\deg{f(x)}=n\\), write</p> \\[f(x)=x^n+a_{n-1}x^{n-1}+\\cdots+a_0\\quad (a_i\\in F)\\] <p>Define the companion matrix \\(C\\) of \\(f(x)\\) to be the following \\(n\\times n\\) matrix</p> \\[ C=\\begin{bmatrix} 0 &amp;&amp; 0 &amp;&amp; \\cdots &amp;&amp; 0 &amp;&amp; -a_0 \\\\ 1 &amp;&amp; 0 &amp;&amp;  \\cdots &amp;&amp; 0 &amp;&amp; -a_1 \\\\ 0 &amp;&amp; 1 &amp;&amp; \\cdots &amp;&amp; 0 &amp;&amp; -a_2 \\\\ \\vdots &amp;&amp; \\vdots &amp;&amp; \\ddots &amp;&amp; \\vdots &amp;&amp; \\vdots \\\\ 0 &amp;&amp; \\cdots &amp;&amp; \\cdots &amp;&amp; 1 &amp;&amp; -a_{n-1} \\end{bmatrix} \\] <p>and is denoted by \\(C(f(x))\\).</p> <p>Let \\(f(x)\\in F[x]\\) be a monic polynomial and \\(C=C(f(x))\\) be its companion matrix, its characteristic polynomial \\(\\chi_C(x)\\) and minimal polynomial \\(\\mu_C(x)\\) can be shown to be \\(f(x)\\).</p> <p>To compute \\(\\chi_C(x)\\), expand from the definition of \\(\\chi_C(x)=\\det(xI - C)\\) and use basic properties of determinant of matrices it can be deduced that \\(\\chi_C(x)=f(x)\\). To prove that \\(\\mu_C(x) = f(x)\\), suppose that \\(\\deg(\\mu_C(x)) = d &lt; n\\), then a non-trivial linear combination of the standard basis in \\(F^n\\) can be constructed, which contradicts to the definition of a basis. Hence \\(d=n\\) and \\(\\mu_C(x) = \\chi_C(x)\\) as \\(\\chi_C(C) = O\\) by direct verification where \\(O = O_{n\\times n}\\) is the \\(n\\times n\\) zero matrix$.</p> <p>Speaking of the rank of a companion matrix \\(C=C(f(x))\\), it can be immediately summarized as follows:</p> <ul> <li>If \\(C\\) is non-singular, then \\(\\text{rank}(C) = n\\).</li> <li>If \\(C\\) is singular (i.e., when \\(f(0) = a_0 = 0\\)), then \\(\\text{rank}(C) = n-1\\).</li> </ul> <p>Let \\(C = C(f(x))\\) be the companion matrix of a monic \\(f(x)\\in F[x]\\), it can be argued that \\(C\\) is the matrix representation of linear operator \\(T: V \\to V\\) on a finite-dimensional vector space \\(V\\) over a field \\(F\\) with respect to some ordered basis \\(\\beta\\) in \\(V\\). The construction is: let \\(V=F^n\\) and \\(T:V\\to V\\) defined by \\(T(v)=Cv\\), the left multiplication of \\(v\\) by \\(C\\). and let \\(\\beta=\\{e_1, T(e_1), \\cdots, T^{n-1}(e_1)\\}\\). By the definition of \\(C\\), \\(beta\\) is linearly independent over \\(F\\) and therefore is a basis for \\(V\\). By the definition of the matrix representation,</p> \\[[T]_{\\beta} = C(f(x))\\] <p>Let \\(V\\) be a finite-dimensional vector space over \\(F\\) and \\(T:V\\to V\\) be a linear operator. Let \\(v\\in V\\). consider the \\(T\\)-annihilator \\(\\mu_v(x)\\) of \\(v\\), the monic polynomial \\(p(x)\\in F[x]\\) with minimal degree such that \\(p(T)v=0\\). Let \\(\\mu_v(x) = f(x)\\) and \\(\\deg(f(x)) = n\\). Consider the set \\(\\beta=\\{v, T(v),\\ldots,T^{n-1}(v)\\}\\). Define</p> \\[C_v = \\text{span}(\\beta)\\] <p>The subspace \\(C_v\\) of \\(V\\) will be called the cyclic subspace of \\(v\\) (in \\(V\\)). Note that \\(C_v\\) depends on the underlying \\(T\\) as well but is usually omitted as the linear operator \\(T\\) being discussed is fixed throughout the context.</p> <p>By the definition of \\(C_v\\), \\(C_v\\) is \\(T\\)-invariant subspace of \\(V\\). Consider \\(T|_{C_v}\\), the linear operator induced by \\(T\\) on \\(C_v\\). Elementary facts about \\(T|_{C_v}\\) are: the characteristic polynomial \\(\\chi_{T_{C_v}}(x)\\) and minimal polynomial \\(\\mu_{T|_{C_v}}(x)\\) of \\(T|_{C_v}\\) are the same and equal to \\(\\mu_v(x) = f(x)\\). Also by the definition of \\(\\mu_v(x)\\) and that of \\(\\mu_T(x)\\) and \\(\\chi_T(x)\\),</p> \\[\\mu_v(x)\\mid \\mu_T(x), \\mu_v(x)\\mid \\chi_T(x)\\] <p>The importance of companion matrices is that they appear as the building blocks in some matrix representation of a linear operator on a finite-dimensional vector space over a field with respect to a particular basis. Such matrix representations are the so-called Rational Canonical Forms, and the existence theorem of such bases is the Cyclic Decomposition Theorem.</p> <p>In essence, to derive the Cyclic Decomposition Theorem, a special case where \\(\\mu_T(x)\\) is a power of an irreducible polynomial is being considered first and such well-behaved basis can be obtained. Later one can reduce the general case (no restriction on \\(\\mu_T(x)\\)) to that special case and assemble those bases together to one for the original vector space.</p> <p>Let \\(V\\) be a finite-dimensional vector space over F and \\(T:V \\to V\\) be a linear operator on \\(V\\). Suppose that \\(\\mu_T(x) = q(x)^m\\) where \\(q(x)\\) is a monic irreducible polynomial in \\(F[x]\\). Then there are cyclic subspaces \\(C_{v_1}, \\cdots, C_{v_{\\ell}}\\) such that \\(V=\\bigoplus_{i=1}^{\\ell}{C_{v_i}}\\), and \\(\\chi_{T|_{C_{v_i}}}(x) = \\mu_{T|_{C_{v_i}}}(x) = q(x)^{m_{i}}\\) with \\(m = m_1 \\ge m_2 \\ge \\cdots \\ge m_{\\ell}\\). Let \\(\\beta\\) be the ordered set derived from the cyclic bases of \\(V_{v_1}, \\cdots, V_{v_{\\ell}}\\), then</p> \\[ [T]_{\\beta}=\\begin{bmatrix} C(q(x)^{m_1}) &amp;&amp; O &amp;&amp;  O &amp;&amp; \\cdots &amp;&amp; O\\\\ O &amp;&amp; C(q(x)^{m_2}) &amp;&amp;  O &amp;&amp; \\cdots &amp;&amp; O\\\\ O &amp;&amp; O &amp;&amp; C(q(x)^{m_2}) &amp;&amp; \\cdots &amp;&amp; O\\\\ \\vdots &amp;&amp;   &amp;&amp; &amp;&amp; \\ddots &amp;&amp; \\vdots \\\\ O &amp;&amp; \\cdots &amp;&amp; \\cdots &amp;&amp; O &amp;&amp; C(q(x)^{m_{\\ell}}) \\end{bmatrix} \\] <p>To obtain the Cyclic Decomposition Theorem without assuming that \\(\\mu_T(x) = q(x)^m\\), a modern proof is to use the Primary Decomposition Theorem to decompose \\(V\\) into a direct sum of \\(T\\)-invariant subspaces \\(W_i\\), and consider the linear operator \\(T|_{W_i}\\) induced by \\(T\\) on \\(W_i\\). This consideration recudes to the previous case as \\(T|_{W_i}\\) is now a power of an irreducible polynomial.</p>"},{"location":"on-lagrange-multipliers-proof/","title":"The method of Lagrange multipliers","text":"<p>This article presents a self-contained proof of the method of Lagrange multipliers.</p> <p>\\(\\textbf{Theorem (Method of Lagrange Multipliers)}\\)</p> <p>Let \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\) and \\(\\mathbf{g}: \\mathbb{R}^n \\to \\mathbb{R}^m\\) are both \\(\\mathcal{C}^1\\)-functions and \\(m \\le n\\). Consider the following optimization problem with equality constraints:</p> \\[ \\begin{aligned} \\min_{\\mathbf{x}\\in\\mathbb{R}^n} &amp;\\quad f(\\mathbf{x}) \\\\ \\text{subject to}&amp;\\quad \\mathbf{g}(\\mathbf{x}) = \\mathbf{0}\\tag{P}\\ \\end{aligned} \\] <p>If \\(\\mathbf{x}^*\\in\\mathbb{R}^n\\) is a regular minimizer for the problem \\((P)\\), then there exists \\(\\boldsymbol{\\lambda^*}\\in\\mathbb{R}^m\\) such that</p> \\[Df(\\mathbf{x}^*) + \\boldsymbol{\\lambda^*}^TD\\mathbf{g}(\\mathbf{x}^*) = \\mathbf{0}^T\\tag{1}\\] <p>\\(\\boldsymbol{\\lambda^*}\\) are referred to as Lagrange multipliers. The primary significance of this theorem is that it provides a necessary condition for regular constrained minimizers.</p> <p>\\(\\textbf{Sketch of Proof}\\)</p> <p>The equation \\((1)\\) means that the gradient \\(\\nabla f(\\mathbf{x}^*)\\) of the objective is a linear combination of gradients of constraints \\(\\nabla g_1(\\mathbf{x}^*), \\cdots, \\nabla g_m(\\mathbf{x}^*)\\) where \\(g_1,\\cdots, g_m\\) are the components of \\(\\mathbf{g}\\). Or equivalently,</p> \\[\\nabla f(\\mathbf{x}^*)\\in\\text{im}({D\\mathbf{g}(\\mathbf{x^*})}^T)\\tag{2}\\] <p>where \\(\\text{im}(\\cdot)\\) denotes the image of a linear transformation.</p> <p>It can be shown that</p> \\[\\text{im}({D\\mathbf{g}(\\mathbf{x^*})}^T) = {\\ker(D\\mathbf{g}(\\mathbf{x^*}))}^{\\perp}\\tag{3}\\] <p>To claim \\((3)\\), it suffices to check the following two things:</p> <ol> <li>\\(\\text{im}({D\\mathbf{g}(\\mathbf{x^*})}^T) \\subseteq{\\ker(D\\mathbf{g}(\\mathbf{x^*}))}^{\\perp}\\)</li> <li>\\(\\text{rank}(D\\mathbf{g}(\\mathbf{x^*})^T) = \\dim(\\ker{D\\mathbf{g}(\\mathbf{x^*})}^{\\perp})\\)</li> </ol> <p>\\(1.\\quad(\\subseteq)\\) If \\(\\mathbf{y}\\in\\text{im}(D\\mathbf{g}(\\mathbf{x^*})^T)\\), then \\(\\mathbf{y} = D\\mathbf{g}(\\mathbf{x^*})^T(\\mathbf{x})\\) for some \\(\\mathbf{x}\\in\\mathbf{R}^m\\). For any \\(\\mathbf{v}\\in\\ker{D\\mathbf{g}(\\mathbf{x^*})}\\), we have \\(\\mathbf{y}\\cdot \\mathbf{v} = \\mathbf{x}\\cdot D\\mathbf{g}(\\mathbf{x^*})\\mathbf{v} = \\mathbf{y}\\cdot\\mathbf{0}=0\\). \\(\\heartsuit\\)</p> <p>\\(2.\\quad\\text{rank}(Dg(\\mathbf{x^*})^T) = \\dim(\\ker{Dg(\\mathbf{x^*})}^{\\perp})\\)</p> <p>\\(\\text{rank}(Dg(\\mathbf{x^*})^T) = \\text{rank}(Dg(\\mathbf{x^*}))\\) as every matrix and its transpose have the same rank, and \\(\\text{rank}(Dg(\\mathbf{x^*})) = m\\) by the regularity of \\(\\mathbf{x^*}\\). On the other hand, \\(\\dim(\\ker{Dg(\\mathbf{x^*})}^{\\perp}) = n - \\dim(\\ker{Dg(\\mathbf{x^*})}) = n - (n - m)\\). \\((2)\\) is proved. \\(\\heartsuit\\)</p> <p>Hence \\((3)\\) is checked.</p> <p>With \\((3)\\), it immediately implies that \\((2)\\) holds true if and only if the following condition holds true:</p> \\[\\nabla f(\\mathbf{x}^*)\\in{\\ker(D\\mathbf{g}(\\mathbf{x}^*))}^{\\perp}\\tag{4}\\] <p>Hence the rest of the proof is to show that for each \\(\\mathbf{y}\\in\\ker(D\\mathbf{g}(\\mathbf{x}^*))\\), we have</p> \\[\\nabla f(\\mathbf{x}^*)\\cdot\\mathbf{y} = 0\\] <p>There is also a key result that will be used in the main proof:</p> <p>\\(\\textbf{Theorem 1}\\)</p> <p>Let \\(\\mathbf{g}\\) be as above and \\(\\mathbf{x}\\) is a regular point. Let \\(S\\) be the constraint set:</p> \\[ S = \\{\\mathbf{x}\\in\\mathbb{R}^n\\mid \\mathbf{g}(\\mathbf{x})=\\mathbf{0}\\} \\] <p>If \\(\\mathbf{y}\\in\\ker(D\\mathbf{g}(\\mathbf{x}))\\), then there exists a \\(\\mathcal{C^1}\\)-function \\(\\gamma=\\gamma(t)\\) in \\(S\\), defined near \\(t=0\\) into \\(\\mathbb{R}^m\\), passing through \\(\\mathbf{x}\\) with derivative \\(\\mathbf{y}\\) at \\(\\mathbf{x}\\).</p> <p>The power of this theorem is to characterize the tangent vectors at a regular point on a constraint set. And its proof relies on the implicit function theorem.</p> <p>\\(\\textbf{Proof of Theorem 1}\\)</p> <p>Since \\(\\mathbf{x}\\) is regular, the gradients \\(\\nabla g_1(\\mathbf{x}),\\cdots,\\nabla g_m(\\mathbf{x})\\) are linearly independent. Express \\(\\mathbf{x} = (\\mathbf{a}, \\mathbf{b})\\) where \\(\\mathbf{a}\\in\\mathbb{R}^m\\) and \\(\\mathbf{b}\\in\\mathbb{R}^{n-m}\\). By relabeling the indices of \\(\\mathbf{x}\\) in such a way that the left-hand \\(m\\times m\\) submatrix of \\(D\\mathbf{g}(\\mathbf{x})\\) is invertible.</p> <p>By the implicit function theorem, there exists an open neighborhood \\(W\\subseteq\\mathbb{R}^{n-m}\\) of \\(\\mathbf{b}\\) and a \\(\\mathcal{C}^1\\)-function \\(\\mathbf{h}: W\\to \\mathbb{R}^m\\) with \\(\\mathbf{h}(\\mathbf{b}) = \\mathbf{a}\\) having the following property:</p> \\[ \\mathbf{g}(\\mathbf{h}(\\mathbf{w}), \\mathbf{w}) = 0\\quad\\forall \\mathbf{w}\\in W \\] <p>Define \\(\\varphi: W\\to\\mathbb{R}^n\\) by \\(\\mathbf{w}\\mapsto (\\mathbf{h}(\\mathbf{w}), \\mathbf{w})\\), then</p> \\[\\mathbf{g}(\\varphi(\\mathbf{w})) = \\mathbf{g}((\\mathbf{h}(\\mathbf{w}), \\mathbf{w})) = \\mathbf{0}\\quad\\forall \\mathbf{w}\\in W\\tag{1.1}\\] <p>Note that \\(\\varphi(\\mathbf{b}) = (\\mathbf{h}(\\mathbf{b}), \\mathbf{b}) = \\mathbf{x}\\).</p> <p>By the chain rule, it follows from \\((1.1)\\) that</p> \\[ D\\mathbf{g}(\\varphi(\\mathbf{w}))D\\varphi(\\mathbf{w}) = \\mathbf{0}\\quad\\forall\\mathbf{w}\\in W\\tag{1.2} \\] <p>From the definition of \\(\\varphi\\),</p> \\[ D\\varphi(\\mathbf{w})\\mathbf{w'} = (D\\mathbf{h}(\\mathbf{w})\\mathbf{w'}, \\mathbf{w'})\\quad\\forall\\mathbf{w, w'}\\in W\\tag{1.3} \\] <p>In particular, by letting \\(\\mathbf{w} = \\mathbf{b}\\) in \\((1.2)\\), we obtain</p> \\[ \\text{im}D\\varphi(\\mathbf{b})\\subseteq\\ker{D\\mathbf{g}(\\varphi(\\mathbf{b}))} = \\ker{D\\mathbf{g}(\\mathbf{x})}\\tag{1.4} \\] <p>The dimension \\(\\text{rank}(D\\varphi(\\mathbf{b}))\\) is at least \\(n-m\\) due to \\((1.3)\\), and the dimension \\(\\text{nullity}(D\\mathbf{g}(x))\\) is also \\(n-m\\) by the nullity-rank theorem and the regularity of \\(\\mathbf{x}\\). Hence the relation in \\((1.4)\\) is an equality:</p> \\[ \\text{im}D\\varphi(\\mathbf{b}) = \\ker{D\\mathbf{g}(\\mathbf{x})}\\tag{1.5} \\] <p>Write \\(\\mathbf{y} = (\\mathbf{k}, \\mathbf{l})\\) where \\(\\mathbf{k}\\in\\mathbb{R}^m\\) and \\(\\mathbf{l}\\in\\mathbb{R}^{n-m}\\). By \\((1.5)\\) and \\((1.3)\\), there exists \\(\\mathbf{w}_0\\in W\\) such that</p> \\[ \\mathbf{y} = D\\varphi(\\mathbf{b})\\mathbf{w}_0 = (D\\mathbf{h}(\\mathbf{b})\\mathbf{w}_0, \\mathbf{w}_0)\\tag{1.6} \\] <p>Then it is obvious that \\(\\mathbf{k}=D\\mathbf{h}(\\mathbf{b})\\mathbf{w}_0\\), \\(\\mathbf{l}=\\mathbf{w}_0\\), and we derive from \\((1.6)\\) that</p> \\[ \\mathbf{y} = (D\\mathbf{h}(\\mathbf{b})\\mathbf{l}, \\mathbf{l})\\tag{1.7} \\] <p>Define \\(\\gamma = \\gamma(t)\\) as follows:</p> \\[ \\gamma(t) = \\varphi(\\mathbf{b} + t\\mathbf{l}) = (\\mathbf{h}(\\mathbf{b}+t\\mathbf{l}), \\mathbf{b}+t\\mathbf{l}) \\] <p>Then</p> \\[ \\gamma(0) = \\varphi(\\mathbf{b}) = (\\mathbf{h}(\\mathbf{b}), \\mathbf{b}) = (\\mathbf{a}, \\mathbf{b}) = \\mathbf{x} \\] <p>and from the chain rule and \\((1.7)\\),</p> \\[ \\gamma'(0) = D\\varphi(\\mathbf{b})\\mathbf{l} = (D\\mathbf{h}(\\mathbf{b})\\mathbf{l}, \\mathbf{l}) = (\\mathbf{k}, \\mathbf{l}) = \\mathbf{y} \\] <p>Now the desired curve \\(\\gamma\\) is found and the proof is complete. \\(\\square\\)</p> <p>\\(\\textbf{Proof of Method of Lagrange Multipliers}\\)</p> <p>Let \\(\\mathbf{y}\\in\\ker(D\\mathbf{g}(\\mathbf{x^*}))\\). By \\(\\textbf{Theorem 1}\\), there exist a curve \\(\\gamma = \\gamma(t)\\) and \\(t^*\\in\\mathbb{R}\\) such that</p> \\[\\gamma(t^*) = \\mathbf{x^*}\\quad\\text{and}\\quad \\gamma'(t^*) = \\mathbf{y}\\tag{5}\\] <p>Consider the real-valued function \\(\\varphi(t) = f(\\gamma(t))\\) defined near \\(t=t^*\\). \\(\\varphi\\) admits its local minimum at \\(t = t^*\\) since \\(\\mathbf{x^*}\\) is a minimizer of Problem \\((P)\\). We have</p> \\[\\varphi '(t^*) = 0\\tag{6}\\] <p>By the chain rule and \\((5)\\),</p> \\[\\varphi '(t^*) = Df(\\gamma(t^*))\\gamma'(t^*) = Df(\\mathbf{x^*})\\mathbf{y}\\tag{7}\\] <p>Now \\((4)\\) is an immediate result of \\((6)\\) and \\((7)\\), and this completes the proof. \\(\\square\\)</p>"},{"location":"why_krylov_subspace/","title":"Why Krylov Subspace?","text":"<p>This note serves to remind me why the Krylov subspace is incredbly popular when it comes to numerical linear algebra.</p> <p>We want to solve the linear system \\(Ax = b\\) where \\(A\\) is \\(n\\times n\\) and \\(b\\in\\mathbb{R}^n\\). Let \\(x^*\\) be a solution to this linear system. The goal is to claim that \\(x^*\\in \\mathcal{K}\\stackrel{\\mathrm{def}}{=}\\text{span}(\\{b, Ab, A^2b,\\ldots, A^{n-1}b\\})\\).</p> <p>To prove this statement, we separate it into two cases:</p> <ul> <li>Case 1: \\(A\\) is invertible</li> <li>Case 2: \\(A\\) is not invertible</li> </ul> <p>But by the end of this note, we will realize that the argument can be simply reduced to Case 2. The reason why I still put the Case 1 here is because it makes the whole thought more intuitive to me.</p> <p>Case 1: \\(A\\) is invertible</p> <p>In this case, \\(x^* = A^{-1}b\\). Let \\(f(x)\\) be the characteristic polynomial of \\(A\\), by the Cayley-Hamilton theorem, \\(A\\) satisfies \\(f(x)\\), i.e, \\(f(A) = O\\), therefore \\(x^*\\) can be expressed as the linear combination of a set of vectors \\(b, Ab,\\ldots, A^{n-1}b\\), implying that \\(x^*\\in\\mathcal{K}\\).</p> <p>Case 2: \\(A\\) is not invertible</p> <p>In this case, we still want to proceed with the similar trick we've used in Case 1. So it urges me to express \\(x^*\\) as \\(x^* = A^{\\dagger}b\\) where \\(A^{\\dagger}\\) denotes the pseudo-inverse of \\(A\\). Let \\(A=U\\Sigma V^*\\) be the singular value decomposition (SVD) of \\(A\\) where \\(U\\) and \\(V\\) and unitary, \\(\\Sigma\\) the matrix whose diagonal entries \\(\\sigma_1,\\ldots, \\sigma_r\\) (\\(r\\) being the rank of \\(A\\)) the singular values of \\(A\\) sorted in descending order. Then \\(A^{\\dagger}=V\\Sigma^{-1}U^*\\). Write \\(b=\\sum_{j\\le n}\\beta_j u_j\\) where \\(\\{u_j\\}\\) are the columns of \\(U\\). Rewerite \\(x^*\\) in vector forms (\\(\\{v_j\\}\\) the columns of \\(V\\) below), we have</p> \\[x^*=V\\Sigma^{-1}U^*b=\\left(\\sum_{j\\le r}\\sigma_j^{-1}v_ju_j^*\\right)\\left(\\sum_{j\\le n}\\beta_j u_j\\right)=\\sum_{j\\le r}\\beta_j\\sigma_j^{-1}v_j\\] <p>What is \\(A^kb?\\)</p> \\[A^kb = \\left(\\sum_{j\\le r}\\sigma_j^k u_j v_j^*\\right)b=\\sum_{j\\le r}\\sigma_j^k(v_j^*b)u_j\\] <p>To prove that \\(x^*\\in\\mathcal{K}\\), it suffices to show that \\(\\beta_j\\sigma_j^{-1}v_j = c\\sigma_j^k(v_j^*b)u_j\\) for some \\(c\\in\\mathbb{R}\\) for every \\(j\\le r\\). Or to simplify the notation, \\(v_j = cu_j\\) for some \\(c\\), but it is easily found as we can dot product both sides with \\(u_j\\) and evaluate \\(c\\).</p> <p>We can immediately recognize that Case 2 is actually a generalization of Case 1 since every matrix admits the singular value decomposition.</p> <p>We are now gaining more familiarity with the Krylov subspaces, and we are able to absorb the ideas of the Conjugate Gradient, MINRES, and GMRES algorithms more easily.</p>"},{"location":"stochastic-calculus/simple/","title":"Notes on Stochastic Calculus","text":""},{"location":"stochastic-calculus/simple/#articles","title":"Articles","text":"<ul> <li>\u6578\u5b78\u50b3\u64ad \uff5c \u8ca1\u52d9\u6578\u5b78</li> <li>Doob, J. L. (1971). What is a martingale?. The American Mathematical Monthly, 78(5), 451-463. [PDF]</li> <li>Harrison, J. M., &amp; Kreps, D. M. (1979). Martingales and arbitrage in multiperiod securities markets. Journal of Economic theory, 20(3), 381-408. [PDF]</li> <li>Harrison, J. M., &amp; Pliska, S. R. (1981). Martingales and stochastic integrals in the theory of continuous trading. Stochastic processes and their applications, 11(3), 215-260. [PDF]</li> </ul>"},{"location":"stochastic-calculus/simple/#textbooks","title":"Textbooks","text":"<ul> <li>Ross, S. M. (1995). Stochastic processes. John Wiley &amp; Sons. [PDF]</li> <li>Williams, D. (1991). Probability with martingales. Cambridge university press. [PDF]</li> <li>Steele, J. M. (2001). Stochastic calculus and financial applications (Vol. 1, p. 722). New York: Springer. [PDF]</li> <li>Capinski, M., &amp; Zastawniak, T. (2003). Mathematics for finance. An Introduction, 118-124. [PDF]</li> <li>Blyth, S. (2014). An introduction to quantitative finance. Oxford University Press. [PDF]</li> </ul>"},{"location":"stochastic-calculus/simple/#courses","title":"Courses","text":"<ul> <li>MIT OCW | Topics in Mathematics with Applications in Finance, https://www.youtube.com/playlist?list=PLaLOVNqqD-2G5SSErHfvGqs7ev7kE8_fj</li> <li>IEOR E4706: Foundations of Financial Engineering</li> <li>Stochastic Processes (MATH136/STAT219, Winter 2021)</li> <li>Stochastic Processes (Advanced Probability II), 36-754</li> </ul>"},{"location":"stochastic-calculus/simple/#problem-sets","title":"Problem Sets","text":"<ul> <li>MIT Mathematics of Finance</li> <li>Stochastic calculus (M2 - 2023)</li> <li>QuantGuide</li> <li>Stochastic Models Quiz</li> <li>18.S096 | Fall 2013 Assignments</li> </ul>"}]}